{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d562cbd",
   "metadata": {},
   "source": [
    "## Pandas Tutorial_part14\n",
    "**Handle large datasets in pandas-Memory optimization tips for Pandas:** \n",
    "\n",
    "    - here we'll look to how we can optimize memory usage for larger datasets that you're using for your machine learning, general like data science jobs. in Python, we often use Pandas, Numpy, and if you don't know how to use these libraries in a right way, you might use a lot of memory and we all know that data sets for data science are so huge and sometimes your laptop has less memory and it can consumes like majority of it, so let's look to some easy techniques.\n",
    "    - There is a great websit 'pythonspeed.com' for optimizing memory usage for pandas, numpy, and so on... the owner of this site 'Itmar' wrote an article on reducing memory usage in pandas. we all use pandas for our data cleaning, machine learning and data science jobs. there are a few simple techniques which can reduce the memory usage. let's you are analyzing votes data which has 50 columns and you only use two columns, the mistake people keep the dataframe which has 50 columns around through out the sessions. if you need two columns then import sub part of the dataframe instead importing the whole dataframe.\n",
    "    -There are majority of techniques in the mentioned site 'pythonspeed.com' you can check it... "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5391b870",
   "metadata": {},
   "source": [
    "**That's were all about Pandas I had for you...**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
